# agentic_rag.py
import re
import json
import asyncio
from typing import List, Dict, Any, Optional
from sentence_transformers import SentenceTransformer
import chromadb
from chromadb.config import Settings
from gigachat import GigaChat

class AgenticRAGHandler:
    """–ê–≥–µ–Ω—Ç –¥–ª—è –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ —Ä–µ–∑—é–º–µ —Å –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω—ã–º —É—Ç–æ—á–Ω–µ–Ω–∏–µ–º."""
    
    def __init__(self, model: SentenceTransformer, collection, giga_chat):
        self.model = model
        self.collection = collection
        self.giga_chat = giga_chat
        self.max_retries = 3
        
    async def _call_llm_with_retry(self, prompt: str, system_prompt: str = None) -> str:
        """–í—ã–∑–æ–≤ LLM —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏."""
        full_prompt = f"{system_prompt}\n\n{prompt}" if system_prompt else prompt
        
        for attempt in range(self.max_retries):
            try:
                response = self.giga_chat.chat(full_prompt)
                return response.choices[0].message.content.strip()
            except Exception as e:
                if attempt < self.max_retries - 1:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ LLM, –ø–æ–ø—ã—Ç–∫–∞ {attempt+1}/{self.max_retries}: {e}")
                    await asyncio.sleep(1)
                else:
                    raise Exception(f"‚ùå –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –≤—ã–∑–æ–≤–∞ LLM –ø—Ä–æ–≤–∞–ª–∏–ª–∏—Å—å: {e}")
    
    def _parse_agent_response(self, response: str) -> dict:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –∞–≥–µ–Ω—Ç–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –Ω–µ–≤–∞–ª–∏–¥–Ω–æ–≥–æ JSON."""
        import re
        import json
        try:
            # 1. –£–¥–∞–ª—è–µ–º markdown –∫–æ–¥
            cleaned = re.sub(r'```json\n?|\n?```', '', response)
            
            # 2. –£–¥–∞–ª—è–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–µ/–∫–æ–Ω–µ—á–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –∏ –∫–∞–≤—ã—á–∫–∏
            cleaned = cleaned.strip()
            if cleaned.startswith('"') and cleaned.endswith('"'):
                cleaned = cleaned[1:-1]
            
            # 3. –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –≤ —Å—Ç—Ä–æ–∫–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏—è—Ö
            # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Å—Ç—Ä–æ–∫–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏ —ç–∫—Ä–∞–Ω–∏—Ä—É–µ–º –≤ –Ω–∏—Ö –ø–µ—Ä–µ–≤–æ–¥—ã —Å—Ç—Ä–æ–∫
            import json
            def fix_json_strings(match):
                text = match.group(1)
                # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
                text = text.replace('\n', '\\n').replace('\r', '\\r').replace('\t', '\\t')
                text = text.replace('"', '\\"')
                return f'"{text}"'
            
            # –†–µ–≥—É–ª—è—Ä–∫–∞ –¥–ª—è –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è —Å—Ç—Ä–æ–∫–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
            pattern = r'"([^"\\]*(?:\\.[^"\\]*)*)"'
            fixed_json = re.sub(pattern, fix_json_strings, cleaned)
            
            # 4. –ü—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π JSON
            try:
                return json.loads(fixed_json)
            except json.JSONDecodeError as e:
                # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å, –ø—Ä–æ–±—É–µ–º –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
                print(f"‚ö†Ô∏è –ü–µ—Ä–≤–∞—è –ø–æ–ø—ã—Ç–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")
                
                # –£–¥–∞–ª—è–µ–º –≤—Å–µ –Ω–µ–ø–µ—á–∞—Ç–∞–µ–º—ã–µ —Å–∏–º–≤–æ–ª—ã –∫—Ä–æ–º–µ –ø—Ä–æ–±–µ–ª–æ–≤
                import re
                cleaned_final = re.sub(r'[\x00-\x1F\x7F]', ' ', cleaned)
                
                # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ JSON –º–µ–∂–¥—É —Ñ–∏–≥—É—Ä–Ω—ã–º–∏ —Å–∫–æ–±–∫–∞–º–∏
                json_match = re.search(r'\{.*\}', cleaned_final, re.DOTALL)
                if json_match:
                    json_str = json_match.group(0)
                    try:
                        return json.loads(json_str)
                    except json.JSONDecodeError:
                        pass
                
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
                return {
                    "thought_process": "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –æ—Ç–≤–µ—Ç –∞–≥–µ–Ω—Ç–∞",
                    "search_queries": ["React —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫", "Frontend React", "React developer"],
                    "filters": {
                        "location": None,
                        "min_experience_years": None,
                        "required_skills": ["React", "React.js"]
                    },
                    "analysis_instructions": "–ù–∞–π–¥–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –∑–Ω–∞—é—Ç React –∏–ª–∏ React.js.",
                    "requires_refinement": False
                }
                
        except Exception as e:
            print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ JSON: {e}")
            print(f"üìù –ò—Å—Ö–æ–¥–Ω—ã–π –æ—Ç–≤–µ—Ç: {response[:500]}...")
            
            # –°–æ–∑–¥–∞–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ React
            return {
                "thought_process": "–ü–æ–∏—Å–∫ React-—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ (–¥–µ—Ñ–æ–ª—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç)",
                "search_queries": ["React —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫", "Frontend React", "React developer"],
                "filters": {
                    "location": None,
                    "min_experience_years": None,
                    "required_skills": ["React"]
                },
                "analysis_instructions": "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ä–µ–∑—é–º–µ –Ω–∞ –∑–Ω–∞–Ω–∏–µ React.",
                "requires_refinement": False
            }
    
    def _build_filters(self, parsed_response: dict) -> dict:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤ –¥–ª—è ChromaDB –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç–≤–µ—Ç–∞ –∞–≥–µ–Ω—Ç–∞."""
        filters = {}
        conditions = []
        
        # –§–∏–ª—å—Ç—Ä –ø–æ –≥–æ—Ä–æ–¥—É (–∏—Å–ø–æ–ª—å–∑—É–µ–º $eq)
        location = parsed_response.get("filters", {}).get("location")
        if location and location.lower() != "null" and location.lower() != "none":
            city = location.lower()
            conditions.append({"location": {"$eq": city}})
            print(f"üìç –§–∏–ª—å—Ç—Ä –ø–æ –≥–æ—Ä–æ–¥—É: {city}")
        
        # –§–∏–ª—å—Ç—Ä –ø–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–º—É –æ–ø—ã—Ç—É (–∏—Å–ø–æ–ª—å–∑—É–µ–º $gte)
        min_exp = parsed_response.get("filters", {}).get("min_experience_years")
        if min_exp and min_exp != "null" and min_exp != "none":
            try:
                min_months = int(min_exp) * 12
                conditions.append({"total_experience_months": {"$gte": min_months}})
                print(f"üìÖ –§–∏–ª—å—Ç—Ä –ø–æ –æ–ø—ã—Ç—É: –æ—Ç {min_exp} –ª–µ—Ç ({min_months} –º–µ—Å—è—Ü–µ–≤)")
            except (ValueError, TypeError):
                pass
        
        # –í–ê–ñ–ù–û: ChromaDB –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç $contains, –ø–æ—ç—Ç–æ–º—É —É–±–∏—Ä–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ –Ω–∞–≤—ã–∫–∞–º
        # –í–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ –±—É–¥–µ–º –∏—Å–∫–∞—Ç—å –ø–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º –∏ —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∑–∂–µ
        required_skills = parsed_response.get("filters", {}).get("required_skills", [])
        if required_skills and isinstance(required_skills, list):
            valid_skills = []
            for skill in required_skills[:3]:
                if skill and str(skill).lower() not in ["null", "none"]:
                    valid_skills.append(str(skill).lower())
            
            if valid_skills:
                print(f"üîß –ù–∞–≤—ã–∫–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞ (–±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –≤ where): {valid_skills}")
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞–≤—ã–∫–∏ –≤ –æ–±—ä–µ–∫—Ç–µ –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
                self._temp_required_skills = valid_skills
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —É—Å–ª–æ–≤–∏—è
        if conditions:
            if len(conditions) > 1:
                filters = {"$and": conditions}
            else:
                filters = conditions[0]
        
        print(f"üîß –ü–æ—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã –¥–ª—è ChromaDB: {filters}")
        return filters
    
    async def _search_with_refinement(self, 
                                initial_queries: List[str], 
                                filters: Dict[str, Any],
                                max_results: int = 10) -> List[Dict[str, Any]]:
        """–ò—Ç–µ—Ä–∞—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ —Å —É—Ç–æ—á–Ω–µ–Ω–∏–µ–º –∑–∞–ø—Ä–æ—Å–æ–≤."""
        all_resumes = []
        seen_ids = set()
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ç—Ä–µ–±—É–µ–º—ã—Ö –Ω–∞–≤—ã–∫–æ–≤, –µ—Å–ª–∏ –µ—Å—Ç—å
        required_skills = getattr(self, '_temp_required_skills', [])
        
        # –ü–µ—Ä–≤—ã–π —Ä–∞—É–Ω–¥ –ø–æ–∏—Å–∫–∞
        for query in initial_queries:
            if len(all_resumes) >= max_results:
                break
                
            query_emb = self.model.encode(query).tolist()
            results = self.collection.query(
                query_embeddings=[query_emb],
                n_results=min(20, max_results * 3),  # –ë–µ—Ä–µ–º –±–æ–ª—å—à–µ, —á—Ç–æ–±—ã –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å
                where=filters if filters else None,
                include=["documents", "metadatas"]
            )
            
            for doc, meta in zip(results["documents"][0], results["metadatas"][0]):
                resume_id = meta.get("id", "")
                if resume_id and resume_id not in seen_ids:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ç—Ä–µ–±—É–µ–º—ã—Ö –Ω–∞–≤—ã–∫–æ–≤ –≤ –ø–æ–ª–µ all_skills
                    all_skills = meta.get("all_skills", "").lower()
                    
                    # –ï—Å–ª–∏ –µ—Å—Ç—å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –ø–æ –Ω–∞–≤—ã–∫–∞–º, –ø—Ä–æ–≤–µ—Ä—è–µ–º –∏—Ö
                    if required_skills:
                        has_required_skill = False
                        for skill in required_skills:
                            if skill in all_skills:
                                has_required_skill = True
                                break
                        
                        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –Ω—É–∂–Ω—ã–π –Ω–∞–≤—ã–∫, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —ç—Ç–æ —Ä–µ–∑—é–º–µ
                        if not has_required_skill:
                            continue
                    
                    seen_ids.add(resume_id)
                    all_resumes.append({
                        "id": resume_id,
                        "url": meta.get("url", "").strip(),
                        "position": meta.get("desired_position", ""),
                        "location": meta.get("location", ""),
                        "experience_months": meta.get("total_experience_months", 0),
                        "skills": all_skills,
                        "text": doc
                    })
        
        print(f"üîç –ü–µ—Ä–≤—ã–π —Ä–∞—É–Ω–¥ –¥–∞–ª {len(all_resumes)} —Ä–µ–∑—é–º–µ")
        
        # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º
        if len(all_resumes) >= max_results // 2:
            return all_resumes[:max_results]
        
        # –í—Ç–æ—Ä–æ–π —Ä–∞—É–Ω–¥: –ø–æ–∏—Å–∫ –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–æ–≤ –ø–æ –Ω–∞–≤—ã–∫–∞–º
        print("üîç –ü—Ä–æ–±—É—é fallback (–±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –Ω–∞–≤—ã–∫–∞–º)...")
        
        # –û—Å–ª–∞–±–ª—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã: —É–±–∏—Ä–∞–µ–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –ø–æ –Ω–∞–≤—ã–∫–∞–º
        for query in initial_queries:
            if len(all_resumes) >= max_results:
                break
                
            query_emb = self.model.encode(query).tolist()
            results = self.collection.query(
                query_embeddings=[query_emb],
                n_results=min(15, max_results * 2),
                where=filters if filters else None,  # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –±–∞–∑–æ–≤—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã (–≥–æ—Ä–æ–¥, –æ–ø—ã—Ç)
                include=["documents", "metadatas"]
            )
            
            for doc, meta in zip(results["documents"][0], results["metadatas"][0]):
                resume_id = meta.get("id", "")
                if resume_id and resume_id not in seen_ids:
                    seen_ids.add(resume_id)
                    all_resumes.append({
                        "id": resume_id,
                        "url": meta.get("url", "").strip(),
                        "position": meta.get("desired_position", ""),
                        "location": meta.get("location", ""),
                        "experience_months": meta.get("total_experience_months", 0),
                        "skills": meta.get("all_skills", "").lower(),
                        "text": doc
                    })
        
        print(f"‚úÖ –ò—Ç–æ–≥–æ –Ω–∞–π–¥–µ–Ω–æ {len(all_resumes)} —Ä–µ–∑—é–º–µ")
        return all_resumes[:max_results]
    
    async def process_query(self, user_query: str) -> str:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
        
        # === –®–∞–≥ 1: –ê–≥–µ–Ω—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∑–∞–ø—Ä–æ—Å –∏ –ø–ª–∞–Ω–∏—Ä—É–µ—Ç –ø–æ–∏—Å–∫ ===
        planning_prompt = f'''–¢—ã ‚Äî HR-–∞–Ω–∞–ª–∏—Ç–∏–∫, –∫–æ—Ç–æ—Ä—ã–π –∏—â–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –ø–æ –±–∞–∑–µ —Ä–µ–∑—é–º–µ.

            –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: "{user_query}"

            –¢–≤–æ—è –∑–∞–¥–∞—á–∞:
            1. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å –∏ –≤—ã–¥–µ–ª–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã:
            - –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏/–Ω–∞–≤—ã–∫–∏ (React, Python, ML –∏ —Ç.–¥.)
            - –ì–æ—Ä–æ–¥/–ª–æ–∫–∞—Ü–∏—è (–ú–æ—Å–∫–≤–∞, —É–¥–∞–ª—ë–Ω–Ω–æ –∏ —Ç.–¥.)
            - –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –æ–ø—ã—Ç—É (–æ—Ç 3 –ª–µ—Ç, junior/senior –∏ —Ç.–¥.)
            - –î–æ–ª–∂–Ω–æ—Å—Ç—å (—Ñ—Ä–æ–Ω—Ç–µ–Ω–¥, –±—ç–∫–µ–Ω–¥, data scientist –∏ —Ç.–¥.)

            2. –°—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å 1-3 –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞.

            3. –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä—ã –¥–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è –ø–æ–∏—Å–∫–∞.

            –í–µ—Ä–Ω–∏ –æ—Ç–≤–µ—Ç –≤ –°–¢–†–û–ì–û–ú JSON —Ñ–æ—Ä–º–∞—Ç–µ:
            {{
            "thought_process": "–ö—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞",
            "search_queries": ["–∑–∞–ø—Ä–æ—Å1", "–∑–∞–ø—Ä–æ—Å2"],
            "filters": {{
                "location": null,
                "min_experience_years": null,
                "required_skills": ["React"]
            }},
            "analysis_instructions": "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä–µ–∑—é–º–µ",
            "requires_refinement": false
            }}

            –í–∞–∂–Ω–æ: 
            1. –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –¥–≤–æ–π–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏
            2. –ù–µ —Å—Ç–∞–≤—å –∑–∞–ø—è—Ç—ã–µ –ø–æ—Å–ª–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
            3. –í—Å–µ —Å—Ç—Ä–æ–∫–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É
            4. –ù–µ –¥–æ–±–∞–≤–ª—è–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –≤ JSON
            '''
        
        agent_response = await self._call_llm_with_retry(
            planning_prompt,
            system_prompt="–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø–æ–∏—Å–∫—É IT-—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤. –ë—É–¥—å –∫–æ–Ω–∫—Ä–µ—Ç–µ–Ω –∏ —Ç–æ—á–µ–Ω."
        )
        
        parsed_response = self._parse_agent_response(agent_response)
        print(f"ü§ñ –ê–≥–µ–Ω—Ç –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª –∑–∞–ø—Ä–æ—Å: {parsed_response.get('thought_process', '')}")
        
        # === –®–∞–≥ 2: –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ —Å –≤–æ–∑–º–æ–∂–Ω—ã–º —É—Ç–æ—á–Ω–µ–Ω–∏–µ–º ===
        filters = self._build_filters(parsed_response)
        resumes = await self._search_with_refinement(
            parsed_response.get("search_queries", [user_query]),
            filters,
            max_results=15
        )
        
        if not resumes:
            return "üîç –ü–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Ä–µ–∑—é–º–µ."
        
        # === –®–∞–≥ 3: –ì–æ—Ç–æ–≤–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ ===
        context_parts = []
        for i, r in enumerate(resumes, 1):
            exp_years = r['experience_months'] // 12
            skills_preview = r['skills'][:150] + "..." if len(r['skills']) > 150 else r['skills']
            
            context_parts.append(f"""
–†–µ–∑—é–º–µ #{i}:
–î–æ–ª–∂–Ω–æ—Å—Ç—å: {r['position']}
–ì–æ—Ä–æ–¥: {r['location']}
–û–ø—ã—Ç: {exp_years} –ª–µ—Ç
–ö–ª—é—á–µ–≤—ã–µ –Ω–∞–≤—ã–∫–∏: {skills_preview}
–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ: {r['text'][:300]}...
            """.strip())
        
        context = "\n\n".join(context_parts)
        
        # === –®–∞–≥ 4: –ê–≥–µ–Ω—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ä–µ–∑—é–º–µ ===
        analysis_prompt = f"""
–ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: "{user_query}"

{parsed_response.get("analysis_instructions", "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ä–µ–∑—é–º–µ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∑–∞–ø—Ä–æ—Å—É.")}

–ù–∞–π–¥–µ–Ω–Ω—ã–µ —Ä–µ–∑—é–º–µ:
{context}

–¢–≤–æ—è –∑–∞–¥–∞—á–∞:
1. –û—Ü–µ–Ω–∏—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∫–∞–∂–¥–æ–≥–æ —Ä–µ–∑—é–º–µ –∑–∞–ø—Ä–æ—Å—É "{user_query}"
2. –í—ã–±—Ä–∞—Ç—å —Ç–æ–ª—å–∫–æ —Ç–µ —Ä–µ–∑—é–º–µ, –∫–æ—Ç–æ—Ä—ã–µ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –ø–æ–¥—Ö–æ–¥—è—Ç
3. –£–∫–∞–∑–∞—Ç—å –Ω–æ–º–µ—Ä–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Ä–µ–∑—é–º–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä: 1, 3, 5)
4. –î–∞—Ç—å –∫—Ä–∞—Ç–∫–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Ä–µ–∑—é–º–µ
5. –ï—Å–ª–∏ –Ω–∏ –æ–¥–Ω–æ –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç, —Ç–∞–∫ –∏ —Å–∫–∞–∂–∏

**–í–ù–ò–ú–ê–ù–ò–ï**: –í —Å–≤–æ—ë–º –æ—Ç–≤–µ—Ç–µ —É–∫–∞–∑—ã–≤–∞–π –¢–û–õ–¨–ö–û —Ä–µ–∞–ª—å–Ω—ã–µ –Ω–æ–º–µ—Ä–∞ —Ä–µ–∑—é–º–µ –∏–∑ —Å–ø–∏—Å–∫–∞ –≤—ã—à–µ (1, 2, 3...).

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
**–ê–Ω–∞–ª–∏–∑:**
[–Ω–æ–º–µ—Ä–∞ —Ä–µ–∑—é–º–µ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é] - –∫—Ä–∞—Ç–∫–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –≤—ã–±–æ—Ä–∞.

**–ü–æ–¥—Ö–æ–¥—è—â–∏–µ –∫–∞–Ω–¥–∏–¥–∞—Ç—ã:**
[–Ω–æ–º–µ—Ä]: –î–æ–ª–∂–Ω–æ—Å—Ç—å, –ì–æ—Ä–æ–¥, –û–ø—ã—Ç, –ö–ª—é—á–µ–≤—ã–µ –Ω–∞–≤—ã–∫–∏
"""
        
        analysis = await self._call_llm_with_retry(
            analysis_prompt,
            system_prompt="–¢—ã ‚Äî —Å—Ç—Ä–æ–≥–∏–π HR-–∞–Ω–∞–ª–∏—Ç–∏–∫. –í—ã–±–∏—Ä–∞–π —Ç–æ–ª—å–∫–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤."
        )
        
        # === –®–∞–≥ 5: –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–º–µ—Ä–∞ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Ä–µ–∑—é–º–µ ===
        relevant_indices = []
        lines = analysis.split('\n')
        
        for line in lines:
            # –ò—â–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏–µ–º –Ω–æ–º–µ—Ä–æ–≤
            if re.search(r'^\d+(?:\s*,\s*\d+)*', line.strip()):
                numbers = re.findall(r'\b(\d+)\b', line)
                relevant_indices.extend([int(num)-1 for num in numbers])
            # –ò—â–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –Ω–æ–º–µ—Ä–æ–≤
            else:
                numbers = re.findall(r'\b–†–µ–∑—é–º–µ\s+#?(\d+)\b', line, re.IGNORECASE)
                relevant_indices.extend([int(num)-1 for num in numbers])
        
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ –Ω–µ–≤–µ—Ä–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã
        relevant_indices = sorted(set([idx for idx in relevant_indices if 0 <= idx < len(resumes)]))
        
        # === –®–∞–≥ 6: –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç ===
        final_answer = f"**–ó–∞–ø—Ä–æ—Å:** {user_query}\n\n"
        final_answer += f"**–ê–Ω–∞–ª–∏–∑ –∞–≥–µ–Ω—Ç–∞:**\n{analysis}\n\n"
        
        if relevant_indices:
            final_answer += "üîó **–°—Å—ã–ª–∫–∏ –Ω–∞ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —Ä–µ–∑—é–º–µ:**\n"
            seen_urls = set()
            link_counter = 1
            
            for idx in relevant_indices:
                r = resumes[idx]
                if r['url'] and r['url'] not in seen_urls:
                    seen_urls.add(r['url'])
                    exp_years = r['experience_months'] // 12
                    final_answer += f"{link_counter}. {r['position'] or '–î–æ–ª–∂–Ω–æ—Å—Ç—å –Ω–µ —É–∫–∞–∑–∞–Ω–∞'} "
                    final_answer += f"(–≥. {r['location'] or '–ì–æ—Ä–æ–¥ –Ω–µ —É–∫–∞–∑–∞–Ω'}, –æ–ø—ã—Ç {exp_years} –ª–µ—Ç)\n"
                    final_answer += f"{r['url']}\n\n"
                    link_counter += 1
        else:
            final_answer += "‚ÑπÔ∏è **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –ê–≥–µ–Ω—Ç –Ω–µ –Ω–∞—à—ë–ª –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å –∫—Ä–∏—Ç–µ—Ä–∏–∏ –ø–æ–∏—Å–∫–∞."
        
        return final_answer
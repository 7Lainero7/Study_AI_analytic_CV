import json
import re
import os
from tqdm import tqdm

def parse_experience_to_months(exp_str: str) -> int:
    if not exp_str:
        return 0
    exp_str = re.sub(r'\s+', '', exp_str.lower())
    years = int(re.search(r'(\d+)–ª–µ—Ç', exp_str).group(1)) if re.search(r'(\d+)–ª–µ—Ç', exp_str) else 0
    months = int(re.search(r'(\d+)–º–µ—Å—è—Ü', exp_str).group(1)) if re.search(r'(\d+)–º–µ—Å—è—Ü', exp_str) else 0
    return years * 12 + months

def extract_skills_from_experience(resume: dict) -> set:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–∞–≤—ã–∫–∏ –∏–∑ –±–ª–æ–∫–æ–≤ –≤—Ä–æ–¥–µ '–£—Ä–æ–≤–Ω–∏ –≤–ª–∞–¥–µ–Ω–∏—è –Ω–∞–≤—ã–∫–∞–º–∏JavaScriptVue.js...'"""
    skills = set()
    for exp in resume.get("experience_details", []):
        period = exp.get("period", "")
        # –ò—â–µ–º: –£—Ä–æ–≤–Ω–∏ –≤–ª–∞–¥–µ–Ω–∏—è –Ω–∞–≤—ã–∫–∞–º–∏JavaScriptVue.jsNuxt.js...
        match = re.search(r'—É—Ä–æ–≤–Ω–∏ –≤–ª–∞–¥–µ–Ω–∏—è –Ω–∞–≤—ã–∫–∞–º–∏([a-z–∞-—è—ë0-9\s]+)', period.lower())
        if match:
            raw_skills = match.group(1)
            found_skills = re.findall(r'[a-z–∞-—è—ë0-9]+(?:\.[a-z–∞-—è—ë0-9]+)?', raw_skills)
            for s in found_skills:
                if len(s) > 1:
                    skills.add(s.title())
    return skills

def extract_tech_keywords(text: str) -> list:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –æ–ø–∏—Å–∞–Ω–∏—è."""
    if not text:
        return []
    tech_patterns = {
        'react': ['react', 'react.js', 'reactjs'],
        'vue': ['vue', 'vue.js', 'vuejs', 'nuxt', 'nuxt.js'],
        'angular': ['angular'],
        'jquery': ['jquery'],
        'javascript': ['javascript', 'js', 'ecmascript'],
        'typescript': ['typescript', 'ts'],
        'python': ['python'],
        'django': ['django'],
        'flask': ['flask'],
        'fastapi': ['fastapi'],
        'node': ['node', 'node.js', 'nodejs'],
        'java': ['java'],
        'spring': ['spring'],
        'c#': ['c#', 'c sharp'],
        'php': ['php'],
        'laravel': ['laravel'],
        'ruby': ['ruby'],
        'rails': ['rails'],
        'go': ['go', 'golang'],
        'docker': ['docker'],
        'kubernetes': ['kubernetes', 'k8s'],
        'aws': ['aws', 'amazon web services'],
        'sql': ['sql', 'postgresql', 'mysql', 'oracle'],
        'mongodb': ['mongodb', 'mongo'],
        'redis': ['redis'],
        'git': ['git', 'github', 'gitlab'],
        'html': ['html'],
        'css': ['css', 'sass', 'scss', 'less'],
        'webpack': ['webpack'],
        'redux': ['redux'],
        'graphql': ['graphql'],
        'rest': ['rest', 'rest api'],
        'websocket': ['websocket'],
        'ml': ['–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ', 'ml', 'machine learning'],
        'ai': ['–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç', 'ai', 'artificial intelligence'],
        'data science': ['data science']
    }
    text_lower = text.lower()
    found_tech = set()
    for tech, patterns in tech_patterns.items():
        for pattern in patterns:
            if pattern in text_lower:
                found_tech.add(tech.title())
                break  # –ù–µ –∏—â–µ–º –¥—Ä—É–≥–∏–µ —Å–∏–Ω–æ–Ω–∏–º—ã —Ç–æ–π –∂–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏
    return list(found_tech)

def extract_descriptions(resume: dict) -> str:
    seen = set()
    descs = []
    for exp in resume.get("experience_details", []):
        d = exp.get("description", "").strip()
        if d and d not in seen:
            d = re.sub(r'\s+', ' ', d).replace('\r', '').replace('\n', ' ')
            descs.append(d)
            seen.add(d)
    return " ".join(descs)

def extract_all_skills(resume: dict) -> list:
    skills = set()
    # 1. –û—Å–Ω–æ–≤–Ω—ã–µ –Ω–∞–≤—ã–∫–∏ –∏–∑ —Ä–∞–∑–¥–µ–ª–∞ skills
    for s in (resume.get("skills") or []):
        if s and len(s.strip()) > 1:
            skills.add(s.strip().title())
    # 2. –ù–∞–≤—ã–∫–∏ –∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –±–ª–æ–∫–∞ skills_by_level
    for level_skills in (resume.get("skills_by_level") or {}).values():
        for s in (level_skills or []):
            if s and len(s.strip()) > 1:
                skills.add(s.strip().title())
    # 3. –ù–∞–≤—ã–∫–∏ –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è –æ–ø—ã—Ç–∞ —Ä–∞–±–æ—Ç—ã
    skills.update(extract_skills_from_experience(resume))
    # 4. –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞ "–û —Å–µ–±–µ"
    about_text = resume.get("additional_info", {}).get("about", "")
    if about_text:
        skills.update(extract_tech_keywords(about_text))
    # 5. –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –æ–ø–∏—Å–∞–Ω–∏—è –æ–ø—ã—Ç–∞ (—Å–∞–º–æ–µ –≤–∞–∂–Ω–æ–µ!)
    exp_text = extract_descriptions(resume)
    if exp_text:
        skills.update(extract_tech_keywords(exp_text))
    return sorted(skills)

def extract_education(resume: dict) -> str:
    edu_parts = []
    for item in resume.get("education_details", {}).get("higher", []):
        inst = item.get("institution", "").strip()
        details = item.get("details", "").strip()
        if inst or details:
            edu_parts.append(f"{inst}: {details}" if details else inst)
    return "; ".join(edu_parts) if edu_parts else ""

def clean_location(loc: str) -> str:
    if not loc:
        return ""
    return re.split(r'[,\‚Äì‚Äî]', loc)[0].strip()

def process_resumes(input_path: str, output_dir: str):
    os.makedirs(output_dir, exist_ok=True)
    with open(input_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    resumes = data.get("resumes", [])
    print(f"–ù–∞–π–¥–µ–Ω–æ {len(resumes)} —Ä–µ–∑—é–º–µ. –û–±—Ä–∞–±–æ—Ç–∫–∞...")
    documents = []
    metadata_list = []
    for resume in tqdm(resumes):
        res_id = resume.get("id", "")
        url = resume.get("url", "").strip()
        pos = resume.get("desired_position", "")
        loc = clean_location(resume.get("location_relocation") or resume.get("personal_info", {}).get("location", ""))
        exp_months = parse_experience_to_months(resume.get("total_experience", ""))
        # === –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –ù–ê–í–´–ö–û–í ===
        skills_list = extract_all_skills(resume)
        # === –û–ë–†–ê–ë–û–¢–ö–ê –û–ü–ò–°–ê–ù–ò–Ø –û–ü–´–¢–ê ===
        experience_desc = extract_descriptions(resume)
        # === –û–ë–†–ê–ë–û–¢–ö–ê –û–ë–†–ê–ó–û–í–ê–ù–ò–Ø ===
        edu = extract_education(resume)
        # === –§–û–†–ú–ò–†–û–í–ê–ù–ò–ï –ë–û–ì–ê–¢–û–ì–û –¢–ï–ö–°–¢–û–í–û–ì–û –î–û–ö–£–ú–ï–ù–¢–ê ===
        doc_parts = []
        # 1. –ö–ª—é—á–µ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–æ–π (–¥–ª—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏)
        if pos:
            doc_parts.append(f"–ò—â—É –ø–æ–∑–∏—Ü–∏—é: {pos}")
        if skills_list:
            # –ù–∞–≤—ã–∫–∏ - –í –ù–ê–ß–ê–õ–ï –¥–æ–∫—É–º–µ–Ω—Ç–∞ –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
            doc_parts.append(f"–ö–ª—é—á–µ–≤—ã–µ –Ω–∞–≤—ã–∫–∏: {', '.join(skills_list[:20])}")
        # 2. –õ–æ–∫–∞—Ü–∏—è –∏ –æ–ø—ã—Ç
        if loc:
            doc_parts.append(f"–õ–æ–∫–∞—Ü–∏—è: {loc}")
        if exp_months > 0:
            years = exp_months // 12
            months = exp_months % 12
            exp_text = f"{years} –≥–æ–¥{'–∞' if years % 10 in [2,3,4] and years % 100 not in [12,13,14] else '–æ–≤'}" if years > 0 else ""
            if months > 0:
                exp_text += f" {months} –º–µ—Å—è—Ü{'–∞' if months % 10 in [2,3,4] and months % 100 not in [12,13,14] else '–µ–≤'}" if months > 0 else ""
            doc_parts.append(f"–û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã: {exp_text.strip()}")
        # 3. –û–ø–∏—Å–∞–Ω–∏–µ –æ–ø—ã—Ç–∞ (–æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç)
        if experience_desc:
            clean_desc = re.sub(r'\s+', ' ', experience_desc)
            if len(clean_desc) > 800:
                clean_desc = clean_desc[:800] + "..."
            doc_parts.append(f"–û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã: {clean_desc}")
        # 4. –û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        if edu:
            doc_parts.append(f"–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ: {edu}")
        about = resume.get("additional_info", {}).get("about", "")
        if about and len(about) > 30:
            clean_about = re.sub(r'\s+', ' ', about)
            if len(clean_about) > 200:
                clean_about = clean_about[:200] + "..."
            doc_parts.append(f"–û —Å–µ–±–µ: {clean_about}")
        # 5. –°–ø–µ—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å
        specialty = resume.get("specialty_category", "")
        if specialty:
            doc_parts.append(f"–°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è: {specialty}")
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Ç–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞
        doc_text = "\n".join(doc_parts)
        # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        if len(doc_text.strip()) < 100:
            doc_text = f"–ö–∞–Ω–¥–∏–¥–∞—Ç: {pos or '–Ω–µ —É–∫–∞–∑–∞–Ω–∞'}. –ù–∞–≤—ã–∫–∏: {', '.join(skills_list[:5]) if skills_list else '–Ω–µ —É–∫–∞–∑–∞–Ω—ã'}. –ì–æ—Ä–æ–¥: {loc or '–Ω–µ —É–∫–∞–∑–∞–Ω'}."
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç
        documents.append({"id": res_id, "text": doc_text})
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (—Å –ø–æ–ª–Ω—ã–º —Å–ø–∏—Å–∫–æ–º –Ω–∞–≤—ã–∫–æ–≤ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏)
        metadata_list.append({
            "id": res_id,
            "url": url,
            "desired_position": pos,
            "location": loc,
            "total_experience_months": exp_months,
            "skills": skills_list,  # –ü–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –Ω–∞–≤—ã–∫–æ–≤
            "top_5_skills": skills_list[:5] if skills_list else [],
            "specialty_category": specialty,
            "education": edu
        })
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    with open(os.path.join(output_dir, "documents.jsonl"), "w", encoding="utf-8") as f:
        for doc in documents:
            f.write(json.dumps(doc, ensure_ascii=False) + "\n")
    with open(os.path.join(output_dir, "metadata.jsonl"), "w", encoding="utf-8") as f:
        for meta in metadata_list:
            f.write(json.dumps(meta, ensure_ascii=False) + "\n")
    with open(os.path.join(output_dir, "stats.json"), "w", encoding="utf-8") as f:
        json.dump({
            "total": len(resumes),
            "with_skills": sum(1 for m in metadata_list if m["skills"]),
            "avg_skills_per_resume": sum(len(m["skills"]) for m in metadata_list) / len(metadata_list) if metadata_list else 0,
            "sample_skills": skills_list[:10] if skills_list else []  # –ü—Ä–∏–º–µ—Ä –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö –Ω–∞–≤—ã–∫–æ–≤
        }, f, ensure_ascii=False, indent=2)
    print(f"‚úÖ –ì–æ—Ç–æ–≤–æ! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(resumes)} —Ä–µ–∑—é–º–µ.")
    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: —Å—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–≤—ã–∫–æ–≤ –Ω–∞ —Ä–µ–∑—é–º–µ: {sum(len(m['skills']) for m in metadata_list) / len(metadata_list):.1f}")

if __name__ == "__main__":
    process_resumes("./data/resumes.json", "./data/processed")